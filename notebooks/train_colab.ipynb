{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† SymPanICH-Net v2 ‚Äî Google Colab Training\n",
                "\n",
                "**Text-Guided Symmetry-Aware Panoptic Segmentation for ICH Detection**\n",
                "\n",
                "This notebook trains SymPanICH-Net v2 on Google Colab with GPU acceleration.\n",
                "\n",
                "## Prerequisites\n",
                "- Google Colab Pro (for A100/V100 GPUs)\n",
                "- Dataset uploaded to Google Drive\n",
                "\n",
                "## Steps\n",
                "1. Mount Google Drive\n",
                "2. Clone repository\n",
                "3. Install dependencies\n",
                "4. Configure data path\n",
                "5. Train the model\n",
                "6. Evaluate & download results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ GPU Check & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi\n",
                "import torch\n",
                "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Mount Google Drive & Set Data Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Dataset path in Google Drive\n",
                "DATA_DIR = \"/content/drive/MyDrive/FYP'26/data\"\n",
                "\n",
                "import os\n",
                "if os.path.exists(DATA_DIR):\n",
                "    print(f'‚úÖ Data directory found: {DATA_DIR}')\n",
                "    for item in os.listdir(DATA_DIR):\n",
                "        full = os.path.join(DATA_DIR, item)\n",
                "        if os.path.isdir(full):\n",
                "            print(f'   üìÅ {item}/ ({len(os.listdir(full))} items)')\n",
                "        else:\n",
                "            print(f'   üìÑ {item}')\n",
                "else:\n",
                "    print(f'‚ùå Data directory not found: {DATA_DIR}')\n",
                "    print('   Please update DATA_DIR above to match your Drive path')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Clone Repository & Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!rm -rf /content/FYP26\n",
                "!git clone https://github.com/Babu2107/FYP26.git /content/FYP26\n",
                "%cd /content/FYP26\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -q timm pytorch-lightning nibabel albumentations opencv-python-headless transformers peft scipy scikit-image\n",
                "\n",
                "print('\\n‚úÖ Repository cloned and dependencies installed!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Quick Smoke Test\n",
                "\n",
                "Verify the model builds and runs correctly on GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/FYP26')\n",
                "\n",
                "import torch\n",
                "from src.models.sympanich_net import SymPanICHNetV2\n",
                "\n",
                "# Build model\n",
                "model = SymPanICHNetV2(\n",
                "    backbone_name='swinv2_tiny_window8_256',\n",
                "    pretrained=True,\n",
                "    use_context=False,  # 3ch for quick test\n",
                "    num_queries=50,\n",
                "    num_classes=6,\n",
                "    num_decoder_layers=9,\n",
                ")\n",
                "\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f'Total parameters: {total_params / 1e6:.1f}M')\n",
                "print(f'Trainable parameters: {trainable_params / 1e6:.1f}M')\n",
                "\n",
                "# Forward pass on GPU\n",
                "model.eval()\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = model.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    dummy_img = torch.randn(1, 3, 256, 256).to(device)\n",
                "    dummy_flip = torch.flip(dummy_img, dims=[3])\n",
                "    outputs = model(dummy_img, dummy_flip)\n",
                "\n",
                "print(f'\\n‚úÖ Forward pass successful on {device}!')\n",
                "print(f'   pred_logits: {outputs[\"pred_logits\"].shape}')\n",
                "print(f'   pred_masks:  {outputs[\"pred_masks\"].shape}')\n",
                "print(f'   hv_maps:     {outputs[\"hv_maps\"].shape}')\n",
                "\n",
                "del model\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Train the Model\n",
                "\n",
                "Configure training and launch. Checkpoints auto-saved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "#  TRAINING CONFIGURATION\n",
                "# ==========================================\n",
                "\n",
                "CONFIG = {\n",
                "    # Data\n",
                "    'data_dir': DATA_DIR,\n",
                "    'image_size': 256,\n",
                "    'context_slices': 2,  # 2.5D context (set to 0 for standard 3ch)\n",
                "    \n",
                "    # Training\n",
                "    'max_epochs': 100,\n",
                "    'batch_size': 4,\n",
                "    'gradient_accumulation': 4,  # Effective batch = 16\n",
                "    'num_workers': 2,\n",
                "    'precision': '16-mixed',     # FP16 for speed\n",
                "    \n",
                "    # Model\n",
                "    'backbone': 'swinv2_tiny_window8_256',\n",
                "    'num_queries': 50,\n",
                "    'num_classes': 6,  # 5 hemorrhage types + background\n",
                "    'num_decoder_layers': 9,\n",
                "    \n",
                "    # Optimizer\n",
                "    'lr': 1e-4,\n",
                "    'weight_decay': 0.05,\n",
                "    \n",
                "    # Checkpoints\n",
                "    'checkpoint_dir': '/content/FYP26/checkpoints',\n",
                "    'drive_backup_dir': \"/content/drive/MyDrive/FYP'26/checkpoints\",\n",
                "}\n",
                "\n",
                "print('üìã Training Configuration:')\n",
                "for k, v in CONFIG.items():\n",
                "    print(f'   {k}: {v}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/FYP26')\n",
                "\n",
                "import torch\n",
                "try:\n",
                "    import pytorch_lightning as pl\n",
                "    from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
                "except ImportError:\n",
                "    import lightning as pl\n",
                "    from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
                "\n",
                "from src.training.trainer import SymPanICHNetModule\n",
                "from src.data.datamodule import ICHDataModule\n",
                "\n",
                "# DataModule\n",
                "datamodule = ICHDataModule(\n",
                "    data_dir=CONFIG['data_dir'],\n",
                "    image_size=CONFIG['image_size'],\n",
                "    batch_size=CONFIG['batch_size'],\n",
                "    num_workers=CONFIG['num_workers'],\n",
                "    context_slices=CONFIG['context_slices'],\n",
                ")\n",
                "\n",
                "# Model\n",
                "model = SymPanICHNetModule(\n",
                "    backbone_name=CONFIG['backbone'],\n",
                "    pretrained=True,\n",
                "    num_queries=CONFIG['num_queries'],\n",
                "    num_classes=CONFIG['num_classes'],\n",
                "    num_decoder_layers=CONFIG['num_decoder_layers'],\n",
                "    use_context=CONFIG['context_slices'] > 0,\n",
                "    base_lr=CONFIG['lr'],\n",
                "    weight_decay=CONFIG['weight_decay'],\n",
                "    max_epochs=CONFIG['max_epochs'],\n",
                ")\n",
                "\n",
                "# Callbacks\n",
                "callbacks = [\n",
                "    ModelCheckpoint(\n",
                "        dirpath=CONFIG['checkpoint_dir'],\n",
                "        filename='sympanich-{epoch:02d}-{val/dice:.4f}',\n",
                "        monitor='val/dice', mode='max', save_top_k=3, save_last=True,\n",
                "    ),\n",
                "    EarlyStopping(monitor='val/dice', patience=15, mode='max'),\n",
                "    LearningRateMonitor(logging_interval='step'),\n",
                "]\n",
                "\n",
                "# Trainer\n",
                "trainer = pl.Trainer(\n",
                "    max_epochs=CONFIG['max_epochs'],\n",
                "    accelerator='gpu',\n",
                "    devices=1,\n",
                "    precision=CONFIG['precision'],\n",
                "    callbacks=callbacks,\n",
                "    accumulate_grad_batches=CONFIG['gradient_accumulation'],\n",
                "    gradient_clip_val=1.0,\n",
                "    log_every_n_steps=10,\n",
                ")\n",
                "\n",
                "print('üöÄ Starting training...')\n",
                "trainer.fit(model, datamodule=datamodule)\n",
                "print('\\n‚úÖ Training complete!')\n",
                "print(f'Best model: {callbacks[0].best_model_path}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Backup Checkpoints to Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "import os\n",
                "\n",
                "os.makedirs(CONFIG['drive_backup_dir'], exist_ok=True)\n",
                "\n",
                "checkpoint_dir = CONFIG['checkpoint_dir']\n",
                "if os.path.exists(checkpoint_dir):\n",
                "    for f in os.listdir(checkpoint_dir):\n",
                "        src = os.path.join(checkpoint_dir, f)\n",
                "        dst = os.path.join(CONFIG['drive_backup_dir'], f)\n",
                "        shutil.copy2(src, dst)\n",
                "        print(f'  ‚úÖ Backed up: {f}')\n",
                "    print(f'\\n‚úÖ All checkpoints backed up to: {CONFIG[\"drive_backup_dir\"]}')\n",
                "else:\n",
                "    print('‚ùå No checkpoints found')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Evaluate & Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the best model\n",
                "trainer.test(model, datamodule=datamodule, ckpt_path='best')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample predictions\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as mpatches\n",
                "import numpy as np\n",
                "from src.utils.visualization import CLASS_COLORS, CLASS_NAMES, colorize_mask, overlay_mask\n",
                "from src.utils.panoptic_fusion import panoptic_fusion\n",
                "from src.models.report_generator import ReportGenerator\n",
                "\n",
                "model.eval()\n",
                "model = model.to('cuda')\n",
                "\n",
                "# Get test batch\n",
                "datamodule.setup('test')\n",
                "batch = next(iter(datamodule.test_dataloader()))\n",
                "\n",
                "with torch.no_grad():\n",
                "    images = batch['image'].cuda()\n",
                "    images_flip = batch['image_flipped'].cuda()\n",
                "    outputs = model(images, images_flip)\n",
                "\n",
                "# Visualize each sample in the batch\n",
                "B = min(images.shape[0], 4)  # Show up to 4 samples\n",
                "fig, axes = plt.subplots(B, 4, figsize=(20, 5 * B))\n",
                "if B == 1:\n",
                "    axes = axes.reshape(1, -1)\n",
                "\n",
                "reporter = ReportGenerator(image_size=256)\n",
                "\n",
                "for b in range(B):\n",
                "    img = images[b, :3].cpu().numpy().transpose(1, 2, 0)\n",
                "    gt = batch['mask'][b].numpy()\n",
                "    \n",
                "    # Panoptic fusion\n",
                "    fusion = panoptic_fusion(outputs['pred_logits'][b], outputs['pred_masks'][b])\n",
                "    pred = fusion['semantic_map']\n",
                "    pid = batch['patient_id'][b]\n",
                "    sid = batch['slice_idx'][b]\n",
                "    \n",
                "    # Plot\n",
                "    axes[b, 0].imshow(img[:,:,0], cmap='gray')\n",
                "    axes[b, 0].set_title(f'CT Slice (P{pid}, S{sid})')\n",
                "    axes[b, 0].axis('off')\n",
                "    \n",
                "    axes[b, 1].imshow(overlay_mask(img, gt, alpha=0.5))\n",
                "    axes[b, 1].set_title('Ground Truth')\n",
                "    axes[b, 1].axis('off')\n",
                "    \n",
                "    axes[b, 2].imshow(overlay_mask(img, pred, alpha=0.5))\n",
                "    axes[b, 2].set_title(f'Prediction ({len(fusion[\"segments\"])} det)')\n",
                "    axes[b, 2].axis('off')\n",
                "    \n",
                "    axes[b, 3].imshow(colorize_mask(pred))\n",
                "    axes[b, 3].set_title('Pred Mask')\n",
                "    axes[b, 3].axis('off')\n",
                "\n",
                "# Legend\n",
                "patches = [mpatches.Patch(color=np.array(CLASS_COLORS[i])/255, label=CLASS_NAMES[i]) for i in range(1, 6)]\n",
                "fig.legend(handles=patches, loc='lower center', ncol=5, fontsize=12)\n",
                "plt.suptitle('SymPanICH-Net v2 ‚Äî Predictions', fontsize=16, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('/content/FYP26/results_visualization.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print('\\n‚úÖ Visualization saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Generate AI Clinical Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate report for the last visualized prediction\n",
                "segments = fusion['segments']\n",
                "if segments:\n",
                "    classes = np.array([s['class_id'] for s in segments])\n",
                "    masks = np.stack([s['mask'] for s in segments])\n",
                "    scores = np.array([s['score'] for s in segments])\n",
                "    \n",
                "    report = reporter.generate(\n",
                "        pred_classes=classes,\n",
                "        pred_masks=masks,\n",
                "        pred_scores=scores,\n",
                "        patient_id=f'Patient_{pid}',\n",
                "    )\n",
                "    print(report)\n",
                "else:\n",
                "    print('No hemorrhage detected in this slice.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìù Notes\n",
                "\n",
                "- **Colab Pro** recommended for A100 GPU (40GB VRAM)\n",
                "- **Training time**: ~4-6 hours for 100 epochs on A100\n",
                "- **Checkpoints** auto-backed to Google Drive\n",
                "- **For local inference**: download checkpoint and run:\n",
                "  ```bash\n",
                "  python scripts/visualize.py --checkpoint best.ckpt --num_samples 10\n",
                "  ```"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "machine_shape": "hm",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}