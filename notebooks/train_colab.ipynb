{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† SymPanICH-Net v2 ‚Äî Google Colab Training\n",
                "\n",
                "**Text-Guided Symmetry-Aware Panoptic Segmentation for ICH Detection**\n",
                "\n",
                "This notebook trains SymPanICH-Net v2 on Google Colab with GPU acceleration.\n",
                "\n",
                "## Prerequisites\n",
                "- Google Colab Pro (for A100/V100 GPUs)\n",
                "- Dataset uploaded to Google Drive\n",
                "\n",
                "## Steps\n",
                "1. Mount Google Drive\n",
                "2. Clone repository\n",
                "3. Install dependencies\n",
                "4. Configure data path\n",
                "5. Train the model\n",
                "6. Evaluate & download results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ GPU Check & Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi\n",
                "import torch\n",
                "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Set your data path (MODIFY THIS to your dataset location in Drive)\n",
                "DATA_DIR = '/content/drive/MyDrive/FYP26/data'\n",
                "\n",
                "import os\n",
                "if os.path.exists(DATA_DIR):\n",
                "    print(f'‚úÖ Data directory found: {DATA_DIR}')\n",
                "    print(f'   Contents: {os.listdir(DATA_DIR)[:10]}')\n",
                "else:\n",
                "    print(f'‚ùå Data directory not found: {DATA_DIR}')\n",
                "    print('   Please update DATA_DIR to point to your dataset location in Google Drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Clone Repository & Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/Babu2107/FYP26.git /content/FYP26\n",
                "%cd /content/FYP26\n",
                "\n",
                "# Install dependencies\n",
                "!pip install -q -r requirements.txt\n",
                "\n",
                "print('\\n‚úÖ Repository cloned and dependencies installed!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Quick Smoke Test\n",
                "\n",
                "Test that the model builds and can do a forward pass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/FYP26')\n",
                "\n",
                "import torch\n",
                "from src.models.sympanich_net import SymPanICHNetV2\n",
                "\n",
                "# Build model\n",
                "model = SymPanICHNetV2(\n",
                "    backbone_name='swinv2_tiny_window8_256',\n",
                "    pretrained=True,\n",
                "    use_context=False,  # Use 3ch for quick test\n",
                "    num_queries=50,\n",
                "    num_classes=7,\n",
                "    num_decoder_layers=9,\n",
                ")\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f'Total parameters: {total_params / 1e6:.1f}M')\n",
                "print(f'Trainable parameters: {trainable_params / 1e6:.1f}M')\n",
                "\n",
                "# Quick forward pass test\n",
                "model.eval()\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = model.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    dummy_img = torch.randn(1, 3, 256, 256).to(device)\n",
                "    dummy_flip = torch.flip(dummy_img, dims=[3])\n",
                "    outputs = model(dummy_img, dummy_flip)\n",
                "\n",
                "print(f'\\n‚úÖ Forward pass successful!')\n",
                "print(f'   pred_logits: {outputs[\"pred_logits\"].shape}')\n",
                "print(f'   pred_masks:  {outputs[\"pred_masks\"].shape}')\n",
                "print(f'   hv_maps:     {outputs[\"hv_maps\"].shape}')\n",
                "print(f'   text_emb:    {outputs[\"text_embeddings\"].shape}')\n",
                "\n",
                "del model\n",
                "torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Train the Model\n",
                "\n",
                "Configure training parameters and launch training.\n",
                "Checkpoints are saved to `/content/FYP26/checkpoints/` and\n",
                "also backed up to Google Drive."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "#  TRAINING CONFIGURATION ‚Äî MODIFY AS NEEDED\n",
                "# ==========================================\n",
                "\n",
                "CONFIG = {\n",
                "    # Data\n",
                "    'data_dir': DATA_DIR,\n",
                "    'image_size': 256,\n",
                "    'context_slices': 2,  # Set to 0 for standard 3-channel input\n",
                "    \n",
                "    # Training\n",
                "    'max_epochs': 100,\n",
                "    'batch_size': 4,\n",
                "    'gradient_accumulation': 4,  # Effective batch = 16\n",
                "    'num_workers': 2,\n",
                "    'precision': '16-mixed',     # FP16 for faster training\n",
                "    \n",
                "    # Model\n",
                "    'backbone': 'swinv2_tiny_window8_256',\n",
                "    'num_queries': 50,\n",
                "    'num_classes': 7,\n",
                "    'num_decoder_layers': 9,\n",
                "    \n",
                "    # Optimizer\n",
                "    'lr': 1e-4,\n",
                "    'weight_decay': 0.05,\n",
                "    \n",
                "    # Checkpoints\n",
                "    'checkpoint_dir': '/content/FYP26/checkpoints',\n",
                "    'drive_backup_dir': '/content/drive/MyDrive/FYP26/checkpoints',\n",
                "}\n",
                "\n",
                "print('üìã Training Configuration:')\n",
                "for k, v in CONFIG.items():\n",
                "    print(f'   {k}: {v}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/FYP26')\n",
                "\n",
                "import torch\n",
                "try:\n",
                "    import pytorch_lightning as pl\n",
                "    from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
                "except ImportError:\n",
                "    import lightning as pl\n",
                "    from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
                "\n",
                "from src.training.trainer import SymPanICHNetModule\n",
                "from src.data.datamodule import ICHDataModule\n",
                "\n",
                "# DataModule\n",
                "datamodule = ICHDataModule(\n",
                "    data_dir=CONFIG['data_dir'],\n",
                "    image_size=CONFIG['image_size'],\n",
                "    batch_size=CONFIG['batch_size'],\n",
                "    num_workers=CONFIG['num_workers'],\n",
                "    context_slices=CONFIG['context_slices'],\n",
                ")\n",
                "\n",
                "# Model\n",
                "model = SymPanICHNetModule(\n",
                "    backbone_name=CONFIG['backbone'],\n",
                "    pretrained=True,\n",
                "    num_queries=CONFIG['num_queries'],\n",
                "    num_classes=CONFIG['num_classes'],\n",
                "    num_decoder_layers=CONFIG['num_decoder_layers'],\n",
                "    use_context=CONFIG['context_slices'] > 0,\n",
                "    base_lr=CONFIG['lr'],\n",
                "    weight_decay=CONFIG['weight_decay'],\n",
                "    max_epochs=CONFIG['max_epochs'],\n",
                ")\n",
                "\n",
                "# Callbacks\n",
                "callbacks = [\n",
                "    ModelCheckpoint(\n",
                "        dirpath=CONFIG['checkpoint_dir'],\n",
                "        filename='sympanich-{epoch:02d}-{val/dice:.4f}',\n",
                "        monitor='val/dice', mode='max', save_top_k=3, save_last=True,\n",
                "    ),\n",
                "    EarlyStopping(monitor='val/dice', patience=15, mode='max'),\n",
                "    LearningRateMonitor(logging_interval='step'),\n",
                "]\n",
                "\n",
                "# Trainer\n",
                "trainer = pl.Trainer(\n",
                "    max_epochs=CONFIG['max_epochs'],\n",
                "    accelerator='gpu',\n",
                "    devices=1,\n",
                "    precision=CONFIG['precision'],\n",
                "    callbacks=callbacks,\n",
                "    accumulate_grad_batches=CONFIG['gradient_accumulation'],\n",
                "    gradient_clip_val=1.0,\n",
                "    log_every_n_steps=10,\n",
                ")\n",
                "\n",
                "print('üöÄ Starting training...')\n",
                "trainer.fit(model, datamodule=datamodule)\n",
                "print('\\n‚úÖ Training complete!')\n",
                "print(f'Best model: {callbacks[0].best_model_path}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Backup Checkpoints to Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "import os\n",
                "\n",
                "# Backup checkpoints to Drive\n",
                "os.makedirs(CONFIG['drive_backup_dir'], exist_ok=True)\n",
                "\n",
                "checkpoint_dir = CONFIG['checkpoint_dir']\n",
                "if os.path.exists(checkpoint_dir):\n",
                "    for f in os.listdir(checkpoint_dir):\n",
                "        src = os.path.join(checkpoint_dir, f)\n",
                "        dst = os.path.join(CONFIG['drive_backup_dir'], f)\n",
                "        shutil.copy2(src, dst)\n",
                "        print(f'  Backed up: {f}')\n",
                "    print(f'\\n‚úÖ Checkpoints backed up to: {CONFIG[\"drive_backup_dir\"]}')\n",
                "else:\n",
                "    print('‚ùå No checkpoints found')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Evaluate & Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the best model\n",
                "trainer.test(model, datamodule=datamodule, ckpt_path='best')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample predictions\n",
                "from src.utils.visualization import plot_prediction, overlay_mask\n",
                "from src.utils.panoptic_fusion import panoptic_fusion\n",
                "import numpy as np\n",
                "\n",
                "model.eval()\n",
                "model = model.to('cuda')\n",
                "\n",
                "# Get a batch from validation\n",
                "datamodule.setup('test')\n",
                "batch = next(iter(datamodule.test_dataloader()))\n",
                "\n",
                "with torch.no_grad():\n",
                "    images = batch['image'].cuda()\n",
                "    images_flip = batch['image_flipped'].cuda()\n",
                "    outputs = model(images, images_flip)\n",
                "\n",
                "# Visualize first sample\n",
                "img = images[0].cpu().numpy()[:3].transpose(1, 2, 0)  # First 3 channels\n",
                "gt = batch['mask'][0].numpy()\n",
                "\n",
                "# Run panoptic fusion\n",
                "fusion = panoptic_fusion(\n",
                "    outputs['pred_logits'][0],\n",
                "    outputs['pred_masks'][0],\n",
                ")\n",
                "pred = fusion['semantic_map']\n",
                "\n",
                "plot_prediction(img, gt_mask=gt, pred_mask=pred, title='SymPanICH-Net v2 ‚Äî Sample Prediction')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Generate AI Clinical Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models.report_generator import ReportGenerator\n",
                "\n",
                "reporter = ReportGenerator(image_size=256)\n",
                "\n",
                "# Generate report from the first prediction\n",
                "segments = fusion['segments']\n",
                "if segments:\n",
                "    classes = np.array([s['class_id'] for s in segments])\n",
                "    masks = np.stack([s['mask'] for s in segments])\n",
                "    scores = np.array([s['score'] for s in segments])\n",
                "    \n",
                "    report = reporter.generate(\n",
                "        pred_classes=classes,\n",
                "        pred_masks=masks,\n",
                "        pred_scores=scores,\n",
                "        patient_id='Sample_001',\n",
                "    )\n",
                "    print(report)\n",
                "else:\n",
                "    print('No hemorrhage detected in this slice.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìù Notes\n",
                "\n",
                "- **Colab Pro** recommended for A100 GPU access (40GB VRAM)\n",
                "- **Training time**: ~4-6 hours for 100 epochs on A100\n",
                "- **Checkpoints** are auto-saved to Drive on backup\n",
                "- **For inference on your laptop**: download the best checkpoint and run:\n",
                "  ```python\n",
                "  python scripts/predict.py --checkpoint best_model.ckpt --input scan.nii\n",
                "  ```"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "machine_shape": "hm",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}